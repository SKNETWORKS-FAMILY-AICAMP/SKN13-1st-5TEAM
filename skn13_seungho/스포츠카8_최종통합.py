import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
import os
import plotly.express as px
import numpy as np
import seaborn as sns
import requests
from bs4 import BeautifulSoup
from collections import Counter
import re
from datetime import datetime, timedelta
import matplotlib.font_manager as fm

# í•œê¸€ í°íŠ¸ ì„¤ì •
matplotlib.rcParams['font.family'] = 'Malgun Gothic'
matplotlib.rcParams['axes.unicode_minus'] = False

# Streamlit ì•± êµ¬ì„±
st.set_page_config(page_title="ë²•ì¸ì°¨ëŸ‰ ëŒ€ì‹œë³´ë“œ", layout="wide")
menu = st.sidebar.radio("ðŸ“‹ ë©”ë‰´ ì„ íƒ", ["ì°¨ëŸ‰ ë“±ë¡ í˜„í™©", "ì°¨ëŸ‰ ì •ë³´ í•„í„°", "ë‰´ìŠ¤ ì •ë³´", "ìžì£¼ ë¬»ëŠ” ì§ˆë¬¸"])

@st.cache_data
def load_data():
    df = pd.read_csv("car_sales_2023_01_to_2025_03.csv")
    df = df.drop_duplicates(subset=["ìžë™ì°¨ ëª¨ë¸", "ë…„ë„", "ì›”"])  # âœ… ì¤‘ë³µ ì œê±° ì ìš©
    return df

df = load_data()

if menu == "ì°¨ëŸ‰ ë“±ë¡ í˜„í™©":
    st.title("ðŸš— ìˆ˜ìž…ì°¨ ë“±ë¡ í†µê³„ (ì°¨ì¢…ë³„)")

    @st.cache_data
    def load_car_data():
        df = pd.read_csv("car_reg.csv")
        df = df.set_index("ì°¨ì¢…ë³„").T  # ì „ì¹˜: ë‚ ì§œ(ì—´) â†’ ì¸ë±ìŠ¤
        df.index.name = "ì›”"
        df.index = pd.to_datetime(df.index, format='%y%m')
        return df

    car_df = load_car_data()

    selected_models = st.multiselect("ðŸš˜ ì°¨ì¢… ì„ íƒ", car_df.columns.tolist())
    if selected_models:
        df_selected = car_df[selected_models]

        # ðŸ‘‰ ë“±ë¡ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ 5000ëŒ€ ì´ìƒ/ë¯¸ë§Œ ë¶„ë¦¬
        high_volume = [model for model in selected_models if df_selected[model].max() >= 5000]
        low_volume = [model for model in selected_models if df_selected[model].max() < 5000]

        st.subheader("ðŸ“ˆ ë“±ë¡ëŒ€ìˆ˜ 5,000ëŒ€ ì´ìƒ ëª¨ë¸")
        if high_volume:
            st.line_chart(df_selected[high_volume])
        else:
            st.info("5,000ëŒ€ ì´ìƒ ë“±ë¡ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")

        st.subheader("ðŸ“‰ ë“±ë¡ëŒ€ìˆ˜ 5,000ëŒ€ ë¯¸ë§Œ ëª¨ë¸")
        if low_volume:
            st.line_chart(df_selected[low_volume])
        else:
            st.info("5,000ëŒ€ ë¯¸ë§Œ ë“±ë¡ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")

        st.line_chart(df_selected)

        df_recent = df_selected[-24:].copy()
        df_2023 = df_recent[df_recent.index.year == 2023].mean()
        df_2024 = df_recent[df_recent.index.year == 2024].mean()

        st.write("ðŸ“Š í‰ê·  ë“±ë¡ ìˆ˜ (ìµœê·¼ 12ê°œì›”)")
        for model in selected_models:
            col1, col2, col3 = st.columns(3)
            col1.metric(f"ðŸš˜ {model} - 2023 í‰ê· ", f"{df_2023[model]:.0f}ëŒ€")
            col2.metric(f"ðŸš˜ {model} - 2024 í‰ê· ", f"{df_2024[model]:.0f}ëŒ€")
            diff = df_2024[model] - df_2023[model]
            rate = (diff / df_2023[model]) * 100 if df_2023[model] != 0 else 0
            col3.metric("ðŸ“ˆ ì „ë…„ ëŒ€ë¹„ ë³€í™”", f"{diff:+.0f}ëŒ€", f"{rate:+.1f}%")
    else:
        st.info("ë¹„êµí•  ì°¨ì¢…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

elif menu == "ì°¨ëŸ‰ ì •ë³´ í•„í„°":
    st.title("ðŸš˜ ìˆ˜ìž…ì°¨ íŒë§¤ ë°ì´í„° ë¹„êµ (ì—°ë„ë³„/ì›”ë³„ ì‹œê°í™”)")

    available_years = sorted(df["ë…„ë„"].unique())
    selected_years = st.multiselect("ðŸ“† ì—°ë„ ì„ íƒ", available_years, default=available_years)

    car_models = df['ìžë™ì°¨ ëª¨ë¸'].unique()
    selected_models = st.multiselect("ðŸš˜ ëª¨ë¸ ì„ íƒ", car_models)

    excluded = ['ë…„ë„', 'ì›”', 'ìžë™ì°¨ ëª¨ë¸']
    candidate_metrics = [col for col in df.columns if col not in excluded]

    selected_metrics = st.multiselect("ðŸ“Š ë¹„êµ í•­ëª© ì„ íƒ", candidate_metrics)

    if selected_models and selected_metrics and selected_years:
        filtered_df = df[
            (df['ìžë™ì°¨ ëª¨ë¸'].isin(selected_models)) &
            (df['ë…„ë„'].isin(selected_years))
        ].copy()

        if 'ì „ì›”ëŒ€ë¹„_ì¦ê°' in filtered_df.columns:
            filtered_df['ì „ì›”ëŒ€ë¹„_ì¦ê°'] = filtered_df['ì „ì›”ëŒ€ë¹„_ì¦ê°'].astype(str)
            filtered_df['ì „ì›”ëŒ€ë¹„_ì¦ê°'] = filtered_df['ì „ì›”ëŒ€ë¹„_ì¦ê°'].str.extract(r'([+-]?\d+)')[0]
            filtered_df['ì „ì›”ëŒ€ë¹„_ì¦ê°'] = pd.to_numeric(filtered_df['ì „ì›”ëŒ€ë¹„_ì¦ê°'], errors='coerce')

        for metric in selected_metrics:
            fig = px.line(
                filtered_df,
                x="ì›”",
                y=metric,
                color="ìžë™ì°¨ ëª¨ë¸",
                line_dash="ë…„ë„",
                markers=True,
                title=f"{metric} ì›”ë³„ ì¶”ì´ (ì—°ë„ë³„ ë¼ì¸ êµ¬ë¶„)",
            )

            if metric == "ì „ì›”ëŒ€ë¹„_ì¦ê°":
                fig.update_yaxes(zeroline=True, zerolinewidth=2, zerolinecolor='gray')
                fig.update_layout(yaxis_range=[
                    filtered_df[metric].min() - 10,
                    filtered_df[metric].max() + 10
                ])

            fig.update_layout(
                xaxis=dict(tickmode='linear', tick0=1, dtick=1),
                legend_title_text="ìžë™ì°¨ ëª¨ë¸",
                legend=dict(orientation="h", yanchor="bottom", y=-0.3, xanchor="center", x=0.5)
            )
            st.plotly_chart(fig)
    else:
        st.info("ì—°ë„, ëª¨ë¸, ë¹„êµ í•­ëª©ì„ ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”.")

elif menu == "ë‰´ìŠ¤ ì •ë³´":
    st.title("ðŸ“° ë²•ì¸ ê´€ë ¨ ë‰´ìŠ¤")
    st.info("ì´ ì„¹ì…˜ì€ ë‰´ìŠ¤ í¬ë¡¤ë§ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ë‹¤ë¥¸ ê¸°ëŠ¥ì€ ê¸°ì¡´ê³¼ ë™ì¼í•©ë‹ˆë‹¤.")

    QUERY = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ìž…ë ¥í•˜ì„¸ìš”", value="ë²•ì¸ì°¨ ì œë„")
    FILE_PATH = f"news_data/{QUERY}_news.csv"
    os.makedirs("news_data", exist_ok=True)

    def parse_date(text):
        if 'ì¼ ì „' in text:
            return datetime.now() - timedelta(days=int(text.replace('ì¼ ì „', '').strip()))
        elif 'ì‹œê°„ ì „' in text:
            return datetime.now()
        elif '.' in text:
            try:
                return datetime.strptime(text.strip(), "%Y.%m.%d.")
            except:
                return None
        return None

    def crawl_news(query, pages=1):
        data = []
        for page in range(1, pages + 1):
            start = (page - 1) * 10 + 1
            url = f'https://search.naver.com/search.naver?where=news&query={query}&start={start}'
            res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
            soup = BeautifulSoup(res.text, 'html.parser')
            articles = soup.select('div.news_wrap.api_ani_send')

            for article in articles:
                title_tag = article.select_one('a.news_tit')
                if not title_tag:
                    continue
                title = title_tag['title']
                link = title_tag['href']
                press_tag = article.select_one('a.info.press')
                press = press_tag.text.strip() if press_tag else 'Unknown'
                date_tag = article.select('span.info')[-1]
                raw_date = date_tag.text.strip() if date_tag else ''
                parsed = parse_date(raw_date)
                date = parsed.strftime('%Y-%m-%d') if parsed else datetime.today().strftime('%Y-%m-%d')
                summary_tag = article.select_one('div.dsc_wrap')
                summary = summary_tag.text.strip() if summary_tag else ''
                data.append({'title': title, 'press': press, 'date': date, 'summary': summary, 'url': link})
        return pd.DataFrame(data)

    def save_news(df_new):
        if os.path.exists(FILE_PATH):
            df_old = pd.read_csv(FILE_PATH)
            df_all = pd.concat([df_old, df_new]).drop_duplicates(subset=['url'])
        else:
            df_all = df_new
        df_all.to_csv(FILE_PATH, index=False, encoding='utf-8-sig')
        return df_all

    def show_news_paginated(df):
        st.subheader("ðŸ“° ë‰´ìŠ¤ ì œëª© ë° ìš”ì•½ ë³´ê¸° (íŽ˜ì´ì§€ë³„)")
        def truncate(text, limit=100):
            return text if len(text) <= limit else text[:limit] + "..."

        page_size = 10
        total_pages = (len(df) - 1) // page_size + 1
        page = st.number_input("íŽ˜ì´ì§€ ì„ íƒ", min_value=1, max_value=total_pages, step=1)
        start = (page - 1) * page_size
        end = start + page_size

        for i, row in df.iloc[start:end].iterrows():
            st.markdown(f"### ðŸ”— [{row['title']}]({row['url']})")
            st.write(f"ðŸ“ ìš”ì•½: {truncate(row['summary'], 100)}")
            st.markdown("---")

    pages = st.number_input("í¬ë¡¤ë§í•  ë‰´ìŠ¤ íŽ˜ì´ì§€ ìˆ˜ ìž…ë ¥ (10ê°œ ë‹¨ìœ„)", min_value=1, max_value=10, step=1)

    if st.button("ìµœì‹  ë‰´ìŠ¤ í¬ë¡¤ë§í•˜ê¸°"):
        df_today = crawl_news(QUERY, pages)
        df_all = save_news(df_today)
        st.success(f"{len(df_today)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ! ì „ì²´ {len(df_all)}ê±´ ì €ìž¥ë¨.")
    elif os.path.exists(FILE_PATH):
        df_all = pd.read_csv(FILE_PATH)
    else:
        st.warning("ì €ìž¥ëœ ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í¬ë¡¤ë§ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        df_all = pd.DataFrame()

    if not df_all.empty:
        st.subheader("ìµœê·¼ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(df_all[['date', 'title', 'press', 'summary']])

        show_news_paginated(df_all)
    else:
        st.warning("ë‰´ìŠ¤ ë°ì´í„°ê°€ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

elif menu == "ìžì£¼ ë¬»ëŠ” ì§ˆë¬¸":
    st.title("'ì—°ë‘ìƒ‰ ë²ˆí˜¸íŒ' ì •ì±… ê´€ë ¨ ìžì£¼ ë¬»ëŠ” ì§ˆë¬¸")
    st.markdown("""
                ê³ ê°€ ë²•ì¸ì°¨ëŸ‰ ëŒ€ìƒ ì—°ë‘ìƒ‰ ë²ˆí˜¸íŒ ë„ìž… ì •ì±…ê´€ë ¨, ë¬¸ì˜ ë‚´ìš©ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.
                """)
    
    # FAQ ì„¹ì…˜
    with st.expander("Q1. ì—°ë‘ìƒ‰ ë²ˆí˜¸íŒì€ ì–´ë–¤ ì°¨ëŸ‰ì— ë¶€ì°©ë˜ë‚˜ìš”??"):
        st.markdown("""
                    **A:** 8000ë§Œì› ì´ìƒì˜ ë²•ì¸ ì°¨ëŸ‰ì´ ì£¼ìš” ëŒ€ìƒì´ë©°, 
                    1ë…„ ë¯¸ë§Œì˜ ë‹¨ê¸°ë ŒíŠ¸ ì°¨ëŸ‰ì€ ì œì™¸ ë©ë‹ˆë‹¤.
                    """)
    
    with st.expander("Q2. ë²•ì¸ì°¨ëŸ‰ì— ì—°ë‘ìƒ‰ ë²ˆí˜¸íŒì„ ë„ìž…í•œ ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"):
        st.markdown("""
                    **A:** ê³ ê°€ì˜ ìˆ˜ìž…ì°¨ë¥¼ ë²•ì¸ ëª…ì˜ë¡œ ë“±ë¡ í›„ ê°€ì¡±ì´ë‚˜ ê°œì¸ ìš©ë„ë¡œ ì‚¬ìš©í•˜ëŠ” íŽ¸ë²•ì´ ë§Žì•„ì§€ë©´ì„œ,  
                    ì—…ë¬´ ë¹„ìš©ì²˜ë¦¬ì— ì˜í•œ íƒˆì„¸ ë° ê³¼ì„¸ í˜•í‰ì„± ë¬¸ì œë¥¼ ë§‰ê¸° ìœ„í•´ ì œë„ë¥¼ ë„ìž…í•˜ì˜€ìŠµë‹ˆë‹¤.  
                    """)
    
    with st.expander("Q3. ë²•ì¸ì°¨ë¡œ ë“±ë¡í•  ë•Œ ì·¨ë“ê°€ë¥¼ ë‚®ì¶°ì„œ ì‹ ê³ í•˜ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"):
        st.markdown("""
                    **A:** ì˜ë„ì ìœ¼ë¡œ ì·¨ë“ê°€ë¥¼ ë‚®ì¶° ì‹ ê³ í•˜ë©´ ì„¸ë¬´ì¡°ì‚¬ ëŒ€ìƒì´ ë˜ë©°,  
                    ì‹¤ì œë³´ë‹¤ ë‚®ì€ ê°€ê²©ìœ¼ë¡œ ì‹ ê³ í–ˆì„ ê²½ìš° ê°€ì‚°ì„¸ ë“± ë¶ˆì´ìµì„ ë°›ì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.  
                    """)
    
    with st.expander("Q4. ì—°ë‘ìƒ‰ ë²ˆí˜¸íŒì„ ë‹¨ ë²•ì¸ì°¨ëŸ‰ì„ ì‚¬ì ìœ¼ë¡œ ì‚¬ìš©í•  ê²½ìš° ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"):
        st.markdown("""
                    **A:** ì‚¬ì  ì‚¬ìš©ì´ ì ë°œë˜ë©´ ë²•ì¸ì„¸ ê´€ë ¨ ë¶ˆì´ìµê³¼ ë”ë¶ˆì–´ ì„¸ê¸ˆ ì¶”ì§• ë° ê³¼íƒœë£Œê°€ ë¶€ê³¼ë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.  
                    ì •ë¶€ëŠ” ìš´í–‰ê¸°ë¡ë¶€ ì ê²€ì„ í†µí•´ ë‹¨ì†í•  ê³„íšìž…ë‹ˆë‹¤.  
                    """)
    
    with st.expander("Q5. ì •ì±… ì‹œí–‰ ì´í›„ ì–´ë–¤ ë³€í™”ê°€ ìžˆì—ˆë‚˜ìš”?"):
        st.markdown("""
                    **A:** 2024ë…„ ì •ì±… ì‹œí–‰ ì´í›„ ê³ ê°€ ë²•ì¸ì°¨ì˜ ë“±ë¡ë¥ ì´ ê°ì†Œí–ˆìœ¼ë©°,  
                    ì¼ë¶€ ë¸Œëžœë“œëŠ” ì „ë…„ ëŒ€ë¹„ 30~40% ë“±ë¡ ê°ì†Œë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.
                    """)
    
    with st.expander("Q6. ì—°ë‘ìƒ‰ ë²ˆí˜¸íŒì„ ì‹ ê³ í•˜ë©´ í¬ìƒê¸ˆì´ ìžˆë‚˜ìš”?"):
        st.markdown("""
                    **A:** ë„¤. êµ­ê¸°ë²• ì œ84ì¡° ì œ2í•­ì— ë”°ë¼ ì‚¬ì  ì´ìš© ì ë°œ ì‹œ ì¼ì • ê¸°ì¤€ì— ë”°ë¼ **í¬ìƒê¸ˆ**ì´ ì§€ê¸‰ë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.  
                    ë‹¤ë§Œ, ê¸ˆì•¡ì€ ê´€í•  ì§€ìžì²´ ë° ì‹ ê³  ìƒí™©ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
                    """)

# ë§ˆë¬´ë¦¬ ë¬¸êµ¬
    st.divider()
    st.info("ì¶”ê°€ì ì¸ ë¬¸ì˜ì‚¬í•­ì€ ê°œì¸ì ìœ¼ë¡œ ìš”ì²­í•˜ì‹œë©´ ì¶”í›„ì— ë‹µë³€ë“œë¦¬ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.")