{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31536023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# 1. ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ê¸°ì‚¬ ë§í¬ ìˆ˜ì§‘ (ì œëª© í•„í„°ë§ ì œê±°, ìµœëŒ€ 50ê°œ í™•ì¥)\n",
    "def search_naver_news_links(keyword, max_results=50):\n",
    "    headers = {\n",
    "        'User-Agent': (\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
    "            '(KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36'\n",
    "        )\n",
    "    }\n",
    "\n",
    "    collected = []\n",
    "    page = 1\n",
    "\n",
    "    while len(collected) < max_results:\n",
    "        start = (page - 1) * 10 + 1\n",
    "        search_url = f\"https://search.naver.com/search.naver?where=news&query={keyword}&start={start}\"\n",
    "        res = requests.get(search_url, headers=headers)\n",
    "\n",
    "        if res.status_code != 200:\n",
    "            print(f\"âš ï¸ í˜ì´ì§€ {page} ìš”ì²­ ì‹¤íŒ¨ (ì½”ë“œ {res.status_code})\")\n",
    "            break\n",
    "\n",
    "        soup = BeautifulSoup(res.text, 'lxml')\n",
    "        link_tags = soup.select('a.info')\n",
    "\n",
    "        count_this_page = 0\n",
    "        for a in link_tags:\n",
    "            if a.get_text() == \"ë„¤ì´ë²„ë‰´ìŠ¤\":\n",
    "                link = a['href']\n",
    "                title = a.find_previous('a').get_text()\n",
    "                if (title, link) not in collected:\n",
    "                    collected.append((title, link))\n",
    "                    count_this_page += 1\n",
    "            if len(collected) >= max_results:\n",
    "                break\n",
    "\n",
    "        if count_this_page == 0:\n",
    "            break\n",
    "        page += 1\n",
    "\n",
    "    return collected\n",
    "\n",
    "# 2. ê¸°ì‚¬ ë³¸ë¬¸ í¬ë¡¤ë§\n",
    "def get_naver_article_body(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    res = requests.get(url, headers=headers)\n",
    "    if res.status_code != 200:\n",
    "        return \"\"\n",
    "\n",
    "    soup = BeautifulSoup(res.text, \"lxml\")\n",
    "    content = soup.find(\"div\", {\"id\": \"newsct_article\"}) or soup.find(\"div\", {\"class\": \"newsct_article\"})\n",
    "    return content.get_text(separator=\" \").strip() if content else \"\"\n",
    "\n",
    "# 3. íŒë§¤ ìˆ˜ì¹˜ ë° ë³€í™”ìœ¨ ì¶”ì¶œ í•¨ìˆ˜ (ë³€í™”ìœ¨ ê³„ì‚° í¬í•¨)\n",
    "def extract_sales_changes_with_rate(text):\n",
    "    results = []\n",
    "\n",
    "    pattern_change = re.findall(\n",
    "        r'(?P<brand>[ê°€-í£A-Za-z]+).*?(?P<year1>20\\d{2})ë…„.*?(?P<sales1>[\\d,ë§Œ]+)ëŒ€.*?(?P<year2>20\\d{2})ë…„.*?(?P<sales2>[\\d,ë§Œ]+)ëŒ€',\n",
    "        text\n",
    "    )\n",
    "\n",
    "    for brand, y1, s1, y2, s2 in pattern_change:\n",
    "        s1_num = int(s1.replace(',', '').replace('ë§Œ', '0000'))\n",
    "        s2_num = int(s2.replace(',', '').replace('ë§Œ', '0000'))\n",
    "\n",
    "        rate = ((s2_num - s1_num) / s1_num) * 100\n",
    "        direction = \"ì¦ê°€\" if rate > 0 else \"ê°ì†Œ\"\n",
    "        rate_str = f\"{abs(round(rate, 1))}% {direction}\"\n",
    "\n",
    "        results.append({\n",
    "            \"ë¸Œëœë“œ\": brand,\n",
    "            \"ì—°ë„\": y1,\n",
    "            \"íŒë§¤ëŒ€ìˆ˜\": s1_num,\n",
    "            \"ë³€í™”ìœ¨\": None\n",
    "        })\n",
    "        results.append({\n",
    "            \"ë¸Œëœë“œ\": brand,\n",
    "            \"ì—°ë„\": y2,\n",
    "            \"íŒë§¤ëŒ€ìˆ˜\": s2_num,\n",
    "            \"ë³€í™”ìœ¨\": rate_str\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# 4. ì‹¤í–‰\n",
    "def main():\n",
    "    search_keyword = input(\"ğŸ” ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”: \")\n",
    "    print(f\"\\n[ğŸ” '{search_keyword}' ë¡œ ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...]\\n\")\n",
    "\n",
    "    news_list = search_naver_news_links(search_keyword, max_results=50)\n",
    "    all_sales_data = []\n",
    "\n",
    "    for idx, (title, link) in enumerate(news_list, 1):\n",
    "        print(f\"[{idx}] ğŸ“° {title}\")\n",
    "        print(f\"     ğŸ”— {link}\")\n",
    "        body = get_naver_article_body(link)\n",
    "        if not body:\n",
    "            print(\"     âš ï¸ ë³¸ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨\\n\")\n",
    "            continue\n",
    "\n",
    "        sales_data = extract_sales_changes_with_rate(body)\n",
    "        for item in sales_data:\n",
    "            item['ì¶œì²˜ë²ˆí˜¸'] = idx  # ê¸°ì‚¬ ë²ˆí˜¸ ì—°ê²°\n",
    "        all_sales_data.extend(sales_data)\n",
    "        print(\"     âœ… ìˆ˜ì¹˜ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ\\n\")\n",
    "\n",
    "    print(\"\\nğŸ“Š ìµœì¢… íŒë§¤ ìˆ˜ì¹˜ ë° ë³€í™”ìœ¨ ì •ë³´ (ê¸°ì‚¬ ë²ˆí˜¸ ë§¤ì¹­):\\n\")\n",
    "    for item in all_sales_data:\n",
    "        print(f\"[{item['ì¶œì²˜ë²ˆí˜¸']}] ğŸ“Œ ë¸Œëœë“œ: {item['ë¸Œëœë“œ']}, ì—°ë„: {item['ì—°ë„']}, íŒë§¤ëŒ€ìˆ˜: {item['íŒë§¤ëŒ€ìˆ˜']}, ë³€í™”ìœ¨: {item['ë³€í™”ìœ¨']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}