import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
import os
import plotly.express as px
import numpy as np
import seaborn as sns
import requests
from bs4 import BeautifulSoup
from collections import Counter
import re
from datetime import datetime, timedelta
import matplotlib.font_manager as fm
import pymysql



# í•œê¸€ í°íŠ¸ ì„¤ì •
matplotlib.rcParams['font.family'] = 'Malgun Gothic'
matplotlib.rcParams['axes.unicode_minus'] = False

# Streamlit ì•± êµ¬ì„±
st.set_page_config(page_title="ë²•ì¸ì°¨ëŸ‰ ëŒ€ì‹œë³´ë“œ", layout="wide")
menu = st.sidebar.radio("ðŸ“‹ ë©”ë‰´ ì„ íƒ", ["ì°¨ëŸ‰ ë“±ë¡ í˜„í™©","ì°¨ëŸ‰ ì •ë³´ í•„í„°", "ë‰´ìŠ¤ ì •ë³´", "íŠ¸ìœ„í„° ë°˜ì‘", "ìœ íŠœë¸Œ ë°˜ì‘" ,"ìžì£¼ ë¬»ëŠ” ì§ˆë¬¸"])

@st.cache_data
def load_data():
    return pd.read_csv("car_sales_2023_01_to_2025_03.csv")

df = load_data()

###############################################################################################################

import pandas as pd
import streamlit as st
from sqlalchemy import create_engine

if menu == "ì°¨ëŸ‰ ë“±ë¡ í˜„í™©":
    st.title("ðŸš— ìˆ˜ìž… ë²•ì¸ì°¨ëŸ‰ ë“±ë¡ í†µê³„ (ì°¨ì¢…ë³„)")

    # âœ… MySQLì—ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
    @st.cache_data
    def load_car_data_from_mysql():
        db_user = "runnnn"
        db_password = "1111"
        db_host = "localhost"
        db_port = "3306"
        db_name = "car_reg"
        table_name = "car_reg"

        engine = create_engine(f"mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}")
        query = f"SELECT * FROM {table_name}"
        df = pd.read_sql(query, con=engine)
        df = df.set_index("ì°¨ì¢…ë³„").T
        df.index.name = "ì›”"
        df.index = pd.to_datetime(df.index, format="%y%m")
        return df

    car_df = load_car_data_from_mysql()

    selected_models = st.multiselect("ðŸš˜ ì°¨ì¢… ì„ íƒ", car_df.columns.tolist())
    if selected_models:
        df_selected = car_df[selected_models]

        high_volume = [model for model in selected_models if df_selected[model].max() >= 5000]
        low_volume = [model for model in selected_models if df_selected[model].max() < 5000]

        st.subheader("ðŸ“ˆ ë“±ë¡ëŒ€ìˆ˜ 5,000ëŒ€ ì´ìƒ ëª¨ë¸")
        if high_volume:
            st.line_chart(df_selected[high_volume])
        else:
            st.info("5,000ëŒ€ ì´ìƒ ë“±ë¡ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")

        st.subheader("ðŸ“‰ ë“±ë¡ëŒ€ìˆ˜ 5,000ëŒ€ ë¯¸ë§Œ ëª¨ë¸")
        if low_volume:
            st.line_chart(df_selected[low_volume])
        else:
            st.info("5,000ëŒ€ ë¯¸ë§Œ ë“±ë¡ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")

        # ì „ì²´ ì°¨íŠ¸
        st.line_chart(df_selected)

        # ìµœê·¼ 12ê°œì›” í‰ê·  ë¹„êµ
        df_recent = df_selected[-24:].copy()
        df_2023 = df_recent[df_recent.index.year == 2023].mean()
        df_2024 = df_recent[df_recent.index.year == 2024].mean()

        st.write("ðŸ“Š í‰ê·  ë“±ë¡ ìˆ˜ (ìµœê·¼ 12ê°œì›”)")
        for model in selected_models:
            col1, col2, col3 = st.columns(3)
            col1.metric(f"ðŸš˜ {model} - 2023 í‰ê· ", f"{df_2023[model]:.0f}ëŒ€")
            col2.metric(f"ðŸš˜ {model} - 2024 í‰ê· ", f"{df_2024[model]:.0f}ëŒ€")
            diff = df_2024[model] - df_2023[model]
            rate = (diff / df_2023[model]) * 100 if df_2023[model] != 0 else 0
            col3.metric("ðŸ“ˆ ì „ë…„ ëŒ€ë¹„ ë³€í™”", f"{diff:+.0f}ëŒ€", f"{rate:+.1f}%")
    else:
        st.info("ë¹„êµí•  ì°¨ì¢…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")


###############################################################################################################

elif menu == "ì°¨ëŸ‰ ì •ë³´ í•„í„°":
    st.title("ðŸš˜ ìˆ˜ìž…ì°¨ íŒë§¤ ë°ì´í„° ë¹„êµ (ì—°ë„ë³„/ì›”ë³„ ì‹œê°í™”)")

    available_years = sorted(df["ë…„ë„"].unique())
    selected_years = st.multiselect("ðŸ“† ì—°ë„ ì„ íƒ", available_years, default=available_years)

    car_models = df['ìžë™ì°¨ ëª¨ë¸'].unique()
    selected_models = st.multiselect("ðŸš˜ ëª¨ë¸ ì„ íƒ", car_models)

    excluded = ['ë…„ë„', 'ì›”', 'ìžë™ì°¨ ëª¨ë¸']
    candidate_metrics = [col for col in df.columns if col not in excluded]

    selected_metrics = st.multiselect("ðŸ“Š ë¹„êµ í•­ëª© ì„ íƒ", candidate_metrics)

    if selected_models and selected_metrics and selected_years:
        filtered_df = df[
            (df['ìžë™ì°¨ ëª¨ë¸'].isin(selected_models)) &
            (df['ë…„ë„'].isin(selected_years))
        ].copy()

        if 'ì „ì›”ëŒ€ë¹„_ì¦ê°' in filtered_df.columns:
            filtered_df['ì „ì›”ëŒ€ë¹„_ì¦ê°'] = filtered_df['ì „ì›”ëŒ€ë¹„_ì¦ê°'].astype(str)
            filtered_df['ì „ì›”ëŒ€ë¹„_ì¦ê°'] = filtered_df['ì „ì›”ëŒ€ë¹„_ì¦ê°'].str.extract(r'([+-]?\d+)')[0]
            filtered_df['ì „ì›”ëŒ€ë¹„_ì¦ê°'] = pd.to_numeric(filtered_df['ì „ì›”ëŒ€ë¹„_ì¦ê°'], errors='coerce')

        for metric in selected_metrics:
            fig = px.line(
                filtered_df,
                x="ì›”",
                y=metric,
                color="ìžë™ì°¨ ëª¨ë¸",
                line_dash="ë…„ë„",
                markers=True,
                title=f"{metric} ì›”ë³„ ì¶”ì´ (ì—°ë„ë³„ ë¼ì¸ êµ¬ë¶„)",
            )

            if metric == "ì „ì›”ëŒ€ë¹„_ì¦ê°":
                fig.update_yaxes(zeroline=True, zerolinewidth=2, zerolinecolor='gray')
                fig.update_layout(yaxis_range=[
                    filtered_df[metric].min() - 10,
                    filtered_df[metric].max() + 10
                ])

            fig.update_layout(
                xaxis=dict(tickmode='linear', tick0=1, dtick=1),
                legend_title_text="ìžë™ì°¨ ëª¨ë¸",
                legend=dict(orientation="h", yanchor="bottom", y=-0.3, xanchor="center", x=0.5)
            )
            st.plotly_chart(fig)
    else:
        st.info("ì—°ë„, ëª¨ë¸, ë¹„êµ í•­ëª©ì„ ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”.")

###############################################################################################################

elif menu == "ë‰´ìŠ¤ ì •ë³´":
    st.title("ðŸ“° ë²•ì¸ ê´€ë ¨ ë‰´ìŠ¤")
    st.info("ì´ ì„¹ì…˜ì€ ë‰´ìŠ¤ í¬ë¡¤ë§ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ë‹¤ë¥¸ ê¸°ëŠ¥ì€ ê¸°ì¡´ê³¼ ë™ì¼í•©ë‹ˆë‹¤.")

    QUERY = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ìž…ë ¥í•˜ì„¸ìš”", value="ë²•ì¸ì°¨ ì œë„")
    FILE_PATH = f"news_data/{QUERY}_news.csv"
    os.makedirs("news_data", exist_ok=True)

    def parse_date(text):
        if 'ì¼ ì „' in text:
            return datetime.now() - timedelta(days=int(text.replace('ì¼ ì „', '').strip()))
        elif 'ì‹œê°„ ì „' in text:
            return datetime.now()
        elif '.' in text:
            try:
                return datetime.strptime(text.strip(), "%Y.%m.%d.")
            except:
                return None
        return None

    def crawl_news(query, pages=1):
        data = []
        for page in range(1, pages + 1):
            start = (page - 1) * 10 + 1
            url = f'https://search.naver.com/search.naver?where=news&query={query}&start={start}'
            res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
            soup = BeautifulSoup(res.text, 'html.parser')
            articles = soup.select('div.news_wrap.api_ani_send')

            for article in articles:
                title_tag = article.select_one('a.news_tit')
                if not title_tag:
                    continue
                title = title_tag['title']
                link = title_tag['href']
                press_tag = article.select_one('a.info.press')
                press = press_tag.text.strip() if press_tag else 'Unknown'
                date_tag = article.select('span.info')[-1]
                raw_date = date_tag.text.strip() if date_tag else ''
                parsed = parse_date(raw_date)
                date = parsed.strftime('%Y-%m-%d') if parsed else datetime.today().strftime('%Y-%m-%d')
                summary_tag = article.select_one('div.dsc_wrap')
                summary = summary_tag.text.strip() if summary_tag else ''
                data.append({'title': title, 'press': press, 'date': date, 'summary': summary, 'url': link})
        return pd.DataFrame(data)

    def save_news(df_new):
        if os.path.exists(FILE_PATH):
            df_old = pd.read_csv(FILE_PATH)
            df_all = pd.concat([df_old, df_new]).drop_duplicates(subset=['url'])
        else:
            df_all = df_new
        df_all.to_csv(FILE_PATH, index=False, encoding='utf-8-sig')
        return df_all

    def show_news_paginated(df):
        st.subheader("ðŸ“° ë‰´ìŠ¤ ì œëª© ë° ìš”ì•½ ë³´ê¸° (íŽ˜ì´ì§€ë³„)")
        def truncate(text, limit=100):
            return text if len(text) <= limit else text[:limit] + "..."

        page_size = 10
        total_pages = (len(df) - 1) // page_size + 1
        page = st.number_input("íŽ˜ì´ì§€ ì„ íƒ", min_value=1, max_value=total_pages, step=1)
        start = (page - 1) * page_size
        end = start + page_size

        for i, row in df.iloc[start:end].iterrows():
            st.markdown(f"### ðŸ”— [{row['title']}]({row['url']})")
            st.write(f"ðŸ“ ìš”ì•½: {truncate(row['summary'], 100)}")
            st.markdown("---")

    pages = st.number_input("í¬ë¡¤ë§í•  ë‰´ìŠ¤ íŽ˜ì´ì§€ ìˆ˜ ìž…ë ¥ (10ê°œ ë‹¨ìœ„)", min_value=1, max_value=10, step=1)

    if st.button("ìµœì‹  ë‰´ìŠ¤ í¬ë¡¤ë§í•˜ê¸°"):
        df_today = crawl_news(QUERY, pages)
        df_all = save_news(df_today)
        st.success(f"{len(df_today)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ! ì „ì²´ {len(df_all)}ê±´ ì €ìž¥ë¨.")
    elif os.path.exists(FILE_PATH):
        df_all = pd.read_csv(FILE_PATH)
    else:
        st.warning("ì €ìž¥ëœ ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í¬ë¡¤ë§ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        df_all = pd.DataFrame()

    if not df_all.empty:
        st.subheader("ìµœê·¼ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(df_all[['date', 'title', 'press', 'summary']])

        show_news_paginated(df_all)
    else:
        st.warning("ë‰´ìŠ¤ ë°ì´í„°ê°€ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
###############################################################################################################

elif menu == "íŠ¸ìœ„í„° ë°˜ì‘":
    st.title("ðŸš— íŠ¸ìœ„í„° ë°˜ì‘ ìˆ˜ì§‘ ê²°ê³¼ ë³´ê¸°")
    
    csv_file = "tweet_contents.csv"

    # CSV ë¡œë“œ
    @st.cache_data
    def load_data_tw():
        if os.path.exists(csv_file):
            return pd.read_csv(csv_file)
        else:
            return pd.DataFrame(columns=["url", "text"])  # ë¹ˆ ë°ì´í„°í”„ë ˆìž„ ë°˜í™˜
    
    df = load_data_tw()
    
    if df.empty:
        st.error("âŒ tweet_contents.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.success("âœ… CSV íŒŒì¼ ë¡œë”© ì™„ë£Œ!")
    
        search_keyword = st.text_input("ðŸ” í‚¤ì›Œë“œë¡œ ë‚´ìš© ê²€ìƒ‰ (ì˜ˆ: ë²•ì¸, ì—°ë‘ìƒ‰)")
    
        if search_keyword:
            filtered = df[df["text"].str.contains(search_keyword, case=False, na=False)]
    
            if not filtered.empty:
                for _, row in filtered.iterrows():
                    st.markdown(f"**ðŸ“ íŠ¸ìœ— ë‚´ìš©**")
                    st.write(row["text"])
                    st.markdown("---")
            else:
                st.warning("â— ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
                
##############################################################################################################

elif menu == "ìœ íŠœë¸Œ ë°˜ì‘":
    # CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° (íŒŒì¼ëª…ì— ê´„í˜¸ê°€ ìžˆìœ¼ë©´ ì˜¤ë¥˜ ê°€ëŠ¥ â†’ íŒŒì¼ëª… ë³€ê²½ ê¶Œìž¥)
    comments_df = pd.read_csv("comments.csv", header=None)
    comments = comments_df[0].dropna().astype(str)
    
    st.title("ðŸŸ¢ ì—°ë‘ìƒ‰ ë²ˆí˜¸íŒ ê´€ë ¨ ìœ íŠœë¸Œ ëŒ“ê¸€ ë¶„ì„")
    
    # ì´ ëŒ“ê¸€ ìˆ˜ í‘œì‹œ
    st.write(f"ì´ ëŒ“ê¸€ ìˆ˜: {len(comments)}ê°œ")
    
    # ðŸ”Ž í‚¤ì›Œë“œ ê²€ìƒ‰
    search_keyword = st.text_input("ëŒ“ê¸€ ë‚´ í‚¤ì›Œë“œ ê²€ìƒ‰", "")
    if search_keyword:
        filtered = comments[comments.str.contains(search_keyword, case=False)]
        st.write(f"ðŸ” '{search_keyword}'ê°€ í¬í•¨ëœ ëŒ“ê¸€ ìˆ˜: {len(filtered)}ê°œ")
        st.dataframe(filtered)
    
    # ðŸ“Š ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
    st.subheader("ì£¼ìš” í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ")
    
    all_text = " ".join(comments.tolist())
    
    # âœ… font_path ì œê±° â†’ ì‹œìŠ¤í…œ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
    from wordcloud import WordCloud
    import matplotlib.pyplot as plt
    
    text = " ".join(comments.tolist())
    wc = WordCloud(font_path=r"C:\Users\erety\sk_13_5_1st_sungil\1st_pj_g5\ìƒˆ í´ë”\NanumGothicCoding.ttf", width=800, height=400).generate(text)
    
    plt.figure(figsize=(10, 5))
    plt.imshow(wc, interpolation='bilinear')
    plt.axis("off")
    plt.show()
    
    
    plt.imshow(wc, interpolation="bilinear")
    plt.axis("off")
    st.pyplot(plt)


###############################################################################################################

elif menu == "ìžì£¼ ë¬»ëŠ” ì§ˆë¬¸":
    st.title("â“ ìžì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)")

    # MySQLì—ì„œ FAQ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    def load_data_from_mysql(host, user, password, database, table_name="faq"):
        conn = pymysql.connect(
            host=host,
            user=user,
            password=password,
            db=database,
            charset='utf8mb4',
            cursorclass=pymysql.cursors.DictCursor
        )
        with conn.cursor() as cursor:
            cursor.execute(f"SELECT question, answer FROM {table_name}")
            result = cursor.fetchall()
        conn.close()
        return pd.DataFrame(result)

    # Streamlit FAQ íŽ˜ì´ì§€ ì‹¤í–‰ í•¨ìˆ˜
    def render_faq():
        st.write("ì•„ëž˜ ì§ˆë¬¸ì„ í´ë¦­í•˜ë©´ ë‹µë³€ì„ í™•ì¸í•  ìˆ˜ ìžˆì–´ìš”.")
    
        host = "127.0.0.1"
        user = "runnnn"
        password = "1111"
        database = "FAQ"
        table_name = "faq"
    
        try:
            df = load_data_from_mysql(host, user, password, database, table_name)
        except Exception as e:
            st.error(f"ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return
    
        query = st.text_input("ðŸ” ì§ˆë¬¸ ê²€ìƒ‰", "")
        if query:
            df = df[df["question"].str.contains(query, case=False, na=False)]
    
        if df.empty:
            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
    
        for idx, row in enumerate(df.itertuples(index=False), start=1):
            question = str(row.question).strip()
            
            # âœ… ìˆ«ìž ì•žì— ì´ëª¨ì§€ ì¶”ê°€ë¡œ ê°•ì¡° + êµµê²Œ ì²˜ë¦¬
            expander_title = f"ðŸ”¸ **{idx}. {question}**"
            
            with st.expander(expander_title):
                st.write(row.answer)


    # âœ… ì—¬ê¸°ê°€ í•µì‹¬! ë©”ë‰´ì— ì§„ìž…í–ˆì„ ë•Œ ë°”ë¡œ ì‹¤í–‰
    render_faq()

